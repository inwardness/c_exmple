<!DOCTYPE html>

<html lang="en">

<!-- Mirrored from shell-storm.org/x86doc/VPMOVQB_VPMOVSQB_VPMOVUSQB.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 12 Sep 2023 17:02:58 GMT -->
<head>
<meta charset="utf-8">
<title>VPMOVQB/VPMOVSQB/VPMOVUSQB—Down Convert QWord to Byte </title>
<meta name="Description" content="VPMOVQB/VPMOVSQB/VPMOVUSQB—Down Convert QWord to Byte " />
<meta content="VPMOVQB/VPMOVSQB/VPMOVUSQB, x64 opcodes, nasm opcode table, assembly opcode table, intel opcode reference, x86 opcode, instruction reference, assembly opcodes, intel semantics" name="keywords">
<meta name="Viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="Robots" content="index,follow"/>
<link href="style.css" type="text/css" rel="stylesheet">
<script async src="../../www.googletagmanager.com/gtag/jsb2d6?id=G-NLNHL50HG5"></script>
<script src="https://shell-storm.org/assets/js/gtag.js"></script>
</head>
<body><a href="index.html">Back to opcode table</a>
<h1>VPMOVQB/VPMOVSQB/VPMOVUSQB—Down Convert QWord to Byte</h1>
<table>
<tr>
<th>Opcode/Instruction</th>
<th>Op /En</th>
<th>64/32 bit Mode Support</th>
<th>CPUID Feature Flag</th>
<th>Description</th></tr>
<tr>
<td>
<p>EVEX.128.F3.0F38.W0 32 /<em>r</em></p>
<p>VPMOVQB <em>xmm1/m16 {k1}{z}, xmm2</em></p></td>
<td>OVM</td>
<td>V/V</td>
<td>
<p>AVX512VL</p>
<p>AVX512F</p></td>
<td>Converts 2 packed quad-word integers from <em>xmm2 </em>into 2 packed byte integers in <em>xmm1/m16 </em>with truncation under writemask k1.</td></tr>
<tr>
<td>
<p>EVEX.128.F3.0F38.W0 22 /<em>r</em></p>
<p>VPMOVSQB <em>xmm1/m16 {k1}{z}, xmm2</em></p></td>
<td>OVM</td>
<td>V/V</td>
<td>
<p>AVX512VL</p>
<p>AVX512F</p></td>
<td>Converts 2 packed signed quad-word integers from <em>xmm2</em> into 2 packed signed byte integers in <em>xmm1/m16 </em>using<em> </em>signed saturation under writemask k1.</td></tr>
<tr>
<td>
<p>EVEX.128.F3.0F38.W0 12 /<em>r</em></p>
<p>VPMOVUSQB <em>xmm1/m16 {k1}{z}, xmm2</em></p></td>
<td>OVM</td>
<td>V/V</td>
<td>
<p>AVX512VL</p>
<p>AVX512F</p></td>
<td>Converts 2 packed unsigned quad-word integers from <em>xmm2</em> into 2 packed unsigned byte integers in <em>xmm1/m16 </em>using<em> </em>unsigned saturation under writemask k1.</td></tr>
<tr>
<td>
<p>EVEX.256.F3.0F38.W0 32 /<em>r</em></p>
<p>VPMOVQB <em>xmm1/m32 {k1}{z}, ymm2</em></p></td>
<td>OVM</td>
<td>V/V</td>
<td>
<p>AVX512VL</p>
<p>AVX512F</p></td>
<td>Converts 4 packed quad-word integers from <em>ymm2 </em>into 4 packed byte integers in <em>xmm1/m32 </em>with truncation under writemask k1.</td></tr>
<tr>
<td>
<p>EVEX.256.F3.0F38.W0 22 /<em>r</em></p>
<p>VPMOVSQB <em>xmm1/m32 {k1}{z}, ymm2</em></p></td>
<td>OVM</td>
<td>V/V</td>
<td>
<p>AVX512VL</p>
<p>AVX512F</p></td>
<td>Converts 4 packed signed quad-word integers from <em>ymm2</em> into 4 packed signed byte integers in <em>xmm1/m32 </em>using<em> </em>signed saturation under writemask k1.</td></tr>
<tr>
<td>
<p>EVEX.256.F3.0F38.W0 12 /<em>r</em></p>
<p>VPMOVUSQB <em>xmm1/m32 {k1}{z}, ymm2</em></p></td>
<td>OVM</td>
<td>V/V</td>
<td>
<p>AVX512VL</p>
<p>AVX512F</p></td>
<td>Converts 4 packed unsigned quad-word integers from <em>ymm2</em> into 4 packed unsigned byte integers in <em>xmm1/m32 </em>using<em> </em>unsigned saturation under writemask k1.</td></tr>
<tr>
<td>
<p>EVEX.512.F3.0F38.W0 32 /<em>r</em></p>
<p>VPMOVQB <em>xmm1/m64 {k1}{z}, zmm2</em></p></td>
<td>OVM</td>
<td>V/V</td>
<td>AVX512F</td>
<td>Converts 8 packed quad-word integers from <em>zmm2 </em>into 8 packed byte integers in <em>xmm1/m64 </em>with truncation under writemask k1.</td></tr>
<tr>
<td>
<p>EVEX.512.F3.0F38.W0 22 /<em>r</em></p>
<p>VPMOVSQB <em>xmm1/m64 {k1}{z}, zmm2</em></p></td>
<td>OVM</td>
<td>V/V</td>
<td>AVX512F</td>
<td>Converts 8 packed signed quad-word integers from <em>zmm2</em> into 8 packed signed byte integers in <em>xmm1/m64 </em>using<em> </em>signed saturation under writemask k1.</td></tr>
<tr>
<td>
<p>EVEX.512.F3.0F38.W0 12 /<em>r</em></p>
<p>VPMOVUSQB <em>xmm1/m64 {k1}{z}, zmm2</em></p></td>
<td>OVM</td>
<td>V/V</td>
<td>AVX512F</td>
<td>Converts 8 packed unsigned quad-word integers from <em>zmm2</em> into 8 packed unsigned byte integers in <em>xmm1/m64 </em>using<em> </em>unsigned saturation under writemask k1.</td></tr></table>
<h3>Instruction Operand Encoding</h3>
<table>
<tr>
<td>Op/En</td>
<td>Operand 1</td>
<td>Operand 2</td>
<td>Operand 3</td>
<td>Operand 4</td></tr>
<tr>
<td>OVM</td>
<td>ModRM:r/m (w)</td>
<td>ModRM:reg (r)</td>
<td>NA</td>
<td>NA</td></tr></table>
<h2>Description</h2>
<p>VPMOVQB down converts 64-bit integer elements in the source operand (the second operand) into packed byte elements using truncation. VPMOVSQB converts signed 64-bit integers into packed signed bytes using signed satu-ration. VPMOVUSQB convert unsigned quad-word values into unsigned byte values using unsigned saturation. The source operand is a vector register. The destination operand is an XMM register or a memory location.</p>
<p>Down-converted byte elements are written to the destination operand (the first operand) from the least-significant byte. Byte elements of the destination operand are updated according to the writemask. Bits (MAX_VL-1:64) of the destination are zeroed.</p>
<p>EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.</p>
<h2>Operation</h2>
<pre>
</pre>
<strong>VPMOVQB instruction (EVEX encoded versions) when dest is a register</strong>
<pre>
(KL, VL) = (2, 128), (4, 256), (8, 512)
FOR j (cid:197) 0 TO KL-1
    i (cid:197) j * 8
    m (cid:197) j * 64
    IF k1[j] OR *no writemask*
        THEN DEST[i+7:i] (cid:197) TruncateQuadWordToByte (SRC[m+63:m])
        ELSE
        IF *merging-masking*
            ; merging-masking
            THEN *DEST[i+7:i] remains unchanged*
            ELSE *zeroing-masking*
            ; zeroing-masking
            DEST[i+7:i] (cid:197) 0
        FI
    FI;
ENDFOR
DEST[MAX_VL-1:VL/8] (cid:197) 0;
</pre>
<strong>VPMOVQB instruction (EVEX encoded versions) when dest is memory</strong>
<pre>
(KL, VL) = (2, 128), (4, 256), (8, 512)
FOR j (cid:197) 0 TO KL-1
    i (cid:197) j * 8
    m (cid:197) j * 64
    IF k1[j] OR *no writemask*
        THEN DEST[i+7:i] (cid:197) TruncateQuadWordToByte (SRC[m+63:m])
        ELSE
        *DEST[i+7:i] remains unchanged*
        ; merging-masking
    FI;
ENDFOR
</pre>
<strong>VPMOVSQB instruction (EVEX encoded versions) when dest is a register</strong>
<pre>
(KL, VL) = (2, 128), (4, 256), (8, 512)
FOR j (cid:197) 0 TO KL-1
    i (cid:197) j * 8
    m (cid:197) j * 64
    IF k1[j] OR *no writemask*
        THEN DEST[i+7:i] (cid:197) SaturateSignedQuadWordToByte (SRC[m+63:m])
        ELSE
        IF *merging-masking*
            ; merging-masking
            THEN *DEST[i+7:i] remains unchanged*
            ELSE *zeroing-masking*
            ; zeroing-masking
            DEST[i+7:i] (cid:197) 0
        FI
    FI;
ENDFOR
DEST[MAX_VL-1:VL/8] (cid:197) 0;
</pre>
<strong>VPMOVSQB instruction (EVEX encoded versions) when dest is memory</strong>
<pre>
(KL, VL) = (2, 128), (4, 256), (8, 512)
FOR j (cid:197) 0 TO KL-1
    i (cid:197) j * 8
    m (cid:197) j * 64
    IF k1[j] OR *no writemask*
        THEN DEST[i+7:i] (cid:197) SaturateSignedQuadWordToByte (SRC[m+63:m])
        ELSE
        *DEST[i+7:i] remains unchanged*
        ; merging-masking
    FI;
ENDFOR
</pre>
<strong>VPMOVUSQB instruction (EVEX encoded versions) when dest is a register</strong>
<pre>
(KL, VL) = (2, 128), (4, 256), (8, 512)
FOR j (cid:197) 0 TO KL-1
    i (cid:197) j * 8
    m (cid:197) j * 64
    IF k1[j] OR *no writemask*
        THEN DEST[i+7:i] (cid:197) SaturateUnsignedQuadWordToByte (SRC[m+63:m])
        ELSE
        IF *merging-masking*
            ; merging-masking
            THEN *DEST[i+7:i] remains unchanged*
            ELSE *zeroing-masking*
            ; zeroing-masking
            DEST[i+7:i] (cid:197) 0
        FI
    FI;
ENDFOR
DEST[MAX_VL-1:VL/8] (cid:197) 0;
</pre>
<strong>VPMOVUSQB instruction (EVEX encoded versions) when dest is memory</strong>
<pre>
(KL, VL) = (2, 128), (4, 256), (8, 512)
FOR j (cid:197) 0 TO KL-1
    i (cid:197) j * 8
    m (cid:197) j * 64
    IF k1[j] OR *no writemask*
        THEN DEST[i+7:i] (cid:197) SaturateUnsignedQuadWordToByte (SRC[m+63:m])
        ELSE
        *DEST[i+7:i] remains unchanged*
        ; merging-masking
    FI;
ENDFOR
</pre>
<h2>Intel C/C++ Compiler Intrinsic Equivalent</h2>
<pre>
VPMOVQB __m128i _mm512_cvtepi64_epi8( __m512i a);
VPMOVQB __m128i _mm512_mask_cvtepi64_epi8(__m128i s, __mmask8 k, __m512i a);
VPMOVQB __m128i _mm512_maskz_cvtepi64_epi8( __mmask8 k, __m512i a);
VPMOVQB void _mm512_mask_cvtepi64_storeu_epi8(void * d, __mmask8 k, __m512i a);
VPMOVSQB __m128i _mm512_cvtsepi64_epi8( __m512i a);
VPMOVSQB __m128i _mm512_mask_cvtsepi64_epi8(__m128i s, __mmask8 k, __m512i a);
VPMOVSQB __m128i _mm512_maskz_cvtsepi64_epi8( __mmask8 k, __m512i a);
VPMOVSQB void _mm512_mask_cvtsepi64_storeu_epi8(void * d, __mmask8 k, __m512i a);
VPMOVUSQB __m128i _mm512_cvtusepi64_epi8( __m512i a);
VPMOVUSQB __m128i _mm512_mask_cvtusepi64_epi8(__m128i s, __mmask8 k, __m512i a);
VPMOVUSQB __m128i _mm512_maskz_cvtusepi64_epi8( __mmask8 k, __m512i a);
VPMOVUSQB void _mm512_mask_cvtusepi64_storeu_epi8(void * d, __mmask8 k, __m512i a);
VPMOVUSQB __m128i _mm256_cvtusepi64_epi8(__m256i a);
VPMOVUSQB __m128i _mm256_mask_cvtusepi64_epi8(__m128i a, __mmask8 k, __m256i b);
VPMOVUSQB __m128i _mm256_maskz_cvtusepi64_epi8( __mmask8 k, __m256i b);
VPMOVUSQB void _mm256_mask_cvtusepi64_storeu_epi8(void * , __mmask8 k, __m256i b);
VPMOVUSQB __m128i _mm_cvtusepi64_epi8(__m128i a);
VPMOVUSQB __m128i _mm_mask_cvtusepi64_epi8(__m128i a, __mmask8 k, __m128i b);
VPMOVUSQB __m128i _mm_maskz_cvtusepi64_epi8( __mmask8 k, __m128i b);
VPMOVUSQB void _mm_mask_cvtusepi64_storeu_epi8(void * , __mmask8 k, __m128i b);
VPMOVSQB __m128i _mm256_cvtsepi64_epi8(__m256i a);
VPMOVSQB __m128i _mm256_mask_cvtsepi64_epi8(__m128i a, __mmask8 k, __m256i b);
VPMOVSQB __m128i _mm256_maskz_cvtsepi64_epi8( __mmask8 k, __m256i b);
VPMOVSQB void _mm256_mask_cvtsepi64_storeu_epi8(void * , __mmask8 k, __m256i b);
VPMOVSQB __m128i _mm_cvtsepi64_epi8(__m128i a);
VPMOVSQB __m128i _mm_mask_cvtsepi64_epi8(__m128i a, __mmask8 k, __m128i b);
VPMOVSQB __m128i _mm_maskz_cvtsepi64_epi8( __mmask8 k, __m128i b);
VPMOVSQB void _mm_mask_cvtsepi64_storeu_epi8(void * , __mmask8 k, __m128i b);
VPMOVQB __m128i _mm256_cvtepi64_epi8(__m256i a);
VPMOVQB __m128i _mm256_mask_cvtepi64_epi8(__m128i a, __mmask8 k, __m256i b);
VPMOVQB __m128i _mm256_maskz_cvtepi64_epi8( __mmask8 k, __m256i b);
VPMOVQB void _mm256_mask_cvtepi64_storeu_epi8(void * , __mmask8 k, __m256i b);
VPMOVQB __m128i _mm_cvtepi64_epi8(__m128i a);
VPMOVQB __m128i _mm_mask_cvtepi64_epi8(__m128i a, __mmask8 k, __m128i b);
VPMOVQB __m128i _mm_maskz_cvtepi64_epi8( __mmask8 k, __m128i b);
VPMOVQB void _mm_mask_cvtepi64_storeu_epi8(void * , __mmask8 k, __m128i b);
</pre>
<h2>SIMD Floating-Point Exceptions</h2>
<p>None</p>
<h2>Other Exceptions</h2>
<table>
<tr>
<td>EVEX-encoded instruction, see Exceptions Type E6.</td></tr>
<tr>
<td>If EVEX.vvvv != 1111B.</td></tr></table>
</body>

<!-- Mirrored from shell-storm.org/x86doc/VPMOVQB_VPMOVSQB_VPMOVUSQB.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 12 Sep 2023 17:02:58 GMT -->
</html>
