<!DOCTYPE html>

<html lang="en">

<!-- Mirrored from shell-storm.org/x86doc/MOVSHDUP.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 12 Sep 2023 17:02:58 GMT -->
<head>
<meta charset="utf-8">
<title>MOVSHDUP—Replicate Single FP Values </title>
<meta name="Description" content="MOVSHDUP—Replicate Single FP Values " />
<meta content="MOVSHDUP, x64 opcodes, nasm opcode table, assembly opcode table, intel opcode reference, x86 opcode, instruction reference, assembly opcodes, intel semantics" name="keywords">
<meta name="Viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="Robots" content="index,follow"/>
<link href="style.css" type="text/css" rel="stylesheet">
<script async src="../../www.googletagmanager.com/gtag/jsb2d6?id=G-NLNHL50HG5"></script>
<script src="https://shell-storm.org/assets/js/gtag.js"></script>
</head>
<body><a href="index.html">Back to opcode table</a>
<h1>MOVSHDUP—Replicate Single FP Values</h1>
<table>
<tr>
<th>Opcode/Instruction</th>
<th>Op /En</th>
<th>64/32 bit Mode Support</th>
<th>CPUID Feature Flag</th>
<th>Description</th></tr>
<tr>
<td>
<p>F3 0F 16 /r</p>
<p>MOVSHDUP xmm1, xmm2/m128</p></td>
<td>RM</td>
<td>V/V</td>
<td>SSE3</td>
<td>Move odd index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1.</td></tr>
<tr>
<td>
<p>VEX.128.F3.0F.WIG 16 /r</p>
<p>VMOVSHDUP xmm1, xmm2/m128</p></td>
<td>RM</td>
<td>V/V</td>
<td>AVX</td>
<td>Move odd index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1.</td></tr>
<tr>
<td>
<p>VEX.256.F3.0F.WIG 16 /r</p>
<p>VMOVSHDUP ymm1, ymm2/m256</p></td>
<td>RM</td>
<td>V/V</td>
<td>AVX</td>
<td>Move odd index single-precision floating-point values from ymm2/mem and duplicate each element into ymm1.</td></tr>
<tr>
<td>
<p>EVEX.128.F3.0F.W0 16 /r</p>
<p>VMOVSHDUP xmm1 {k1}{z}, xmm2/m128</p></td>
<td>FVM</td>
<td>V/V</td>
<td>
<p>AVX512VL</p>
<p>AVX512F</p></td>
<td>Move odd index single-precision floating-point values from xmm2/m128 and duplicate each element into xmm1 under writemask.</td></tr>
<tr>
<td>
<p>EVEX.256.F3.0F.W0 16 /r</p>
<p>VMOVSHDUP ymm1 {k1}{z}, ymm2/m256</p></td>
<td>FVM</td>
<td>V/V</td>
<td>
<p>AVX512VL</p>
<p>AVX512F</p></td>
<td>Move odd index single-precision floating-point values from ymm2/m256 and duplicate each element into ymm1 under writemask.</td></tr>
<tr>
<td>
<p>EVEX.512.F3.0F.W0 16 /r</p>
<p>VMOVSHDUP zmm1 {k1}{z}, zmm2/m512</p></td>
<td>FVM</td>
<td>V/V</td>
<td>AVX512F</td>
<td>Move odd index single-precision floating-point values from zmm2/m512 and duplicate each element into zmm1 under writemask.</td></tr></table>
<h3>Instruction Operand Encoding</h3>
<table>
<tr>
<td>Op/En</td>
<td>Operand 1</td>
<td>Operand 2</td>
<td>Operand 3</td>
<td>Operand 4</td></tr>
<tr>
<td>RM</td>
<td>ModRM:reg (w)</td>
<td>ModRM:r/m (r)</td>
<td>NA</td>
<td>NA</td></tr>
<tr>
<td>FVM</td>
<td>ModRM:reg (w)</td>
<td>ModRM:r/m (r)</td>
<td>NA</td>
<td>NA</td></tr></table>
<h2>Description</h2>
<p>Duplicates odd-indexed single-precision floating-point values from the source operand (the second operand) to adjacent element pair in the destination operand (the first operand). The source operand is an XMM, YMM or ZMM register or 128, 256 or 512-bit memory location and the destination operand is an XMM, YMM or ZMM register.</p>
<p>128-bit Legacy SSE version: Bits (MAX_VL-1:128) of the corresponding destination register remain unchanged.</p>
<p>VEX.128 encoded version: Bits (MAX_VL-1:128) of the destination register are zeroed.</p>
<p>VEX.256 encoded version: Bits (MAX_VL-1:256) of the destination register are zeroed.</p>
<p>EVEX encoded version: The destination operand is updated at 32-bit granularity according to the writemask.</p>
<p>Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise instructions will #UD.</p>
<h2>Operation</h2>
<pre>
</pre>
<strong>VMOVSHDUP (EVEX encoded versions)</strong>
<pre>
(KL, VL) = (4, 128), (8, 256), (16, 512)
TMP_SRC[31:0] (cid:197) SRC[63:32]
TMP_SRC[63:32] (cid:197) SRC[63:32]
TMP_SRC[95:64] (cid:197) SRC[127:96]
TMP_SRC[127:96] (cid:197) SRC[127:96]
IF VL &gt;= 256
    TMP_SRC[159:128] (cid:197) SRC[191:160]
    TMP_SRC[191:160] (cid:197) SRC[191:160]
    TMP_SRC[223:192] (cid:197) SRC[255:224]
    TMP_SRC[255:224] (cid:197) SRC[255:224]
FI;
IF VL &gt;= 512
    TMP_SRC[287:256] (cid:197) SRC[319:288]
    TMP_SRC[319:288] (cid:197) SRC[319:288]
    TMP_SRC[351:320] (cid:197) SRC[383:352]
    TMP_SRC[383:352] (cid:197) SRC[383:352]
    TMP_SRC[415:384] (cid:197) SRC[447:416]
    TMP_SRC[447:416] (cid:197) SRC[447:416]
    TMP_SRC[479:448] (cid:197) SRC[511:480]
    TMP_SRC[511:480] (cid:197) SRC[511:480]
FI;
FOR j (cid:197) 0 TO KL-1
    i (cid:197) j * 32
    IF k1[j] OR *no writemask*
        THEN DEST[i+31:i] (cid:197) TMP_SRC[i+31:i]
        ELSE
        IF *merging-masking*
            ; merging-masking
            THEN *DEST[i+31:i] remains unchanged*
            ELSE
            ; zeroing-masking
            DEST[i+31:i] (cid:197) 0
        FI
    FI;
ENDFOR
DEST[MAX_VL-1:VL] (cid:197) 0
</pre>
<strong>VMOVSHDUP (VEX.256 encoded version)</strong>
<pre>
DEST[31:0] (cid:197) SRC[63:32]
DEST[63:32] (cid:197) SRC[63:32]
DEST[95:64] (cid:197) SRC[127:96]
DEST[127:96] (cid:197) SRC[127:96]
DEST[159:128] (cid:197) SRC[191:160]
DEST[191:160] (cid:197) SRC[191:160]
DEST[223:192] (cid:197) SRC[255:224]
DEST[255:224] (cid:197) SRC[255:224]
DEST[MAX_VL-1:256] (cid:197) 0
</pre>
<strong>VMOVSHDUP (VEX.128 encoded version)</strong>
<pre>
DEST[31:0] (cid:197) SRC[63:32]
DEST[63:32] (cid:197) SRC[63:32]
DEST[95:64] (cid:197) SRC[127:96]
DEST[127:96] (cid:197) SRC[127:96]
DEST[MAX_VL-1:128] (cid:197) 0
</pre>
<strong>MOVSHDUP (128-bit Legacy SSE version)</strong>
<pre>
DEST[31:0] (cid:197)SRC[63:32]
DEST[63:32] (cid:197)SRC[63:32]
DEST[95:64] (cid:197)SRC[127:96]
DEST[127:96] (cid:197)SRC[127:96]
DEST[MAX_VL-1:128] (Unmodified)
</pre>
<h2>Intel C/C++ Compiler Intrinsic Equivalent</h2>
<pre>
VMOVSHDUP __m512 _mm512_movehdup_ps( __m512 a);
VMOVSHDUP __m512 _mm512_mask_movehdup_ps(__m512 s, __mmask16 k, __m512 a);
VMOVSHDUP __m512 _mm512_maskz_movehdup_ps( __mmask16 k, __m512 a);
VMOVSHDUP __m256 _mm256_mask_movehdup_ps(__m256 s, __mmask8 k, __m256 a);
VMOVSHDUP __m256 _mm256_maskz_movehdup_ps( __mmask8 k, __m256 a);
VMOVSHDUP __m128 _mm_mask_movehdup_ps(__m128 s, __mmask8 k, __m128 a);
VMOVSHDUP __m128 _mm_maskz_movehdup_ps( __mmask8 k, __m128 a);
VMOVSHDUP __m256 _mm256_movehdup_ps (__m256 a);
VMOVSHDUP __m128 _mm_movehdup_ps (__m128 a);
</pre>
<h2>SIMD Floating-Point Exceptions</h2>
<p>None</p>
<h2>Other Exceptions</h2>
<p>Non-EVEX-encoded instruction, see Exceptions Type 4;</p>
<table class="exception-table">
<tr>
<td>EVEX-encoded instruction, see Exceptions Type E4NF.nb.</td></tr>
<tr>
<td>If EVEX.vvvv != 1111B or VEX.vvvv != 1111B.</td></tr></table>
</body>

<!-- Mirrored from shell-storm.org/x86doc/MOVSHDUP.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 12 Sep 2023 17:02:58 GMT -->
</html>
