<!DOCTYPE html>

<html lang="en">

<!-- Mirrored from shell-storm.org/x86doc/CMPSD.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 12 Sep 2023 17:02:58 GMT -->
<head>
<meta charset="utf-8">
<title>CMPSD—Compare Scalar Double-Precision Floating-Point Value </title>
<meta name="Description" content="CMPSD—Compare Scalar Double-Precision Floating-Point Value " />
<meta content="CMPSD, x64 opcodes, nasm opcode table, assembly opcode table, intel opcode reference, x86 opcode, instruction reference, assembly opcodes, intel semantics" name="keywords">
<meta name="Viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="Robots" content="index,follow"/>
<link href="style.css" type="text/css" rel="stylesheet">
<script async src="../../www.googletagmanager.com/gtag/jsb2d6?id=G-NLNHL50HG5"></script>
<script src="https://shell-storm.org/assets/js/gtag.js"></script>
</head>
<body><a href="index.html">Back to opcode table</a>
<h1>CMPSD—Compare Scalar Double-Precision Floating-Point Value</h1>
<table>
<tr>
<th>Opcode/Instruction</th>
<th>Op /En</th>
<th>64/32 bit Mode Support</th>
<th>CPUID Feature Flag</th>
<th>Description</th></tr>
<tr>
<td>F2 0F C2 /r ib CMPSD xmm1, xmm2/m64, imm8</td>
<td>RMI</td>
<td>V/V</td>
<td>SSE2</td>
<td>Compare low double-precision floating-point value in xmm2/m64 and xmm1 using bits 2:0 of imm8 as comparison predicate.</td></tr>
<tr>
<td>VEX.NDS.128.F2.0F.WIG C2 /r ib VCMPSD xmm1, xmm2, xmm3/m64, imm8</td>
<td>RVMI</td>
<td>V/V</td>
<td>AVX</td>
<td>Compare low double-precision floating-point value in xmm3/m64 and xmm2 using bits 4:0 of imm8 as comparison predicate.</td></tr>
<tr>
<td>EVEX.NDS.LIG.F2.0F.W1 C2 /r ib VCMPSD k1 {k2}, xmm2, xmm3/m64{sae}, imm8</td>
<td>T1S</td>
<td>V/V</td>
<td>AVX512F</td>
<td>Compare low double-precision floating-point value in xmm3/m64 and xmm2 using bits 4:0 of imm8 as comparison predicate with writemask k2 and leave the result in mask register k1.</td></tr></table>
<h3>Instruction Operand Encoding</h3>
<table>
<tr>
<td>Op/En</td>
<td>Operand 1</td>
<td>Operand 2</td>
<td>Operand 3</td>
<td>Operand 4</td></tr>
<tr>
<td>RMI</td>
<td>ModRM:reg (r, w)</td>
<td>ModRM:r/m (r)</td>
<td>Imm8</td>
<td>NA</td></tr>
<tr>
<td>RVMI</td>
<td>ModRM:reg (w)</td>
<td>VEX.vvvv</td>
<td>ModRM:r/m (r)</td>
<td>Imm8</td></tr>
<tr>
<td>T1S</td>
<td>ModRM:reg (w)</td>
<td>EVEX.vvvv</td>
<td>ModRM:r/m (r)</td>
<td>Imm8</td></tr></table>
<h2>Description</h2>
<p>Compares the low double-precision floating-point values in the second source operand and the first source operand and returns the results in of the comparison to the destination operand. The comparison predicate operand (imme-diate operand) specifies the type of comparison performed.</p>
<p>128-bit Legacy SSE version: The first source and destination operand (first operand) is an XMM register. The second source operand (second operand) can be an XMM register or 64-bit memory location. Bits (MAX_VL-1:64) of the corresponding YMM destination register remain unchanged. The comparison result is a quadword mask of all 1s (comparison true) or all 0s (comparison false).</p>
<p>VEX.128 encoded version: The first source operand (second operand) is an XMM register. The second source operand (third operand) can be an XMM register or a 64-bit memory location. The result is stored in the low quad-word of the destination operand; the high quadword is filled with the contents of the high quadword of the first source operand. Bits (MAX_VL-1:128) of the destination ZMM register are zeroed. The comparison result is a quad-word mask of all 1s (comparison true) or all 0s (comparison false).</p>
<p>EVEX encoded version: The first source operand (second operand) is an XMM register. The second source operand can be a XMM register or a 64-bit memory location. The destination operand (first operand) is an opmask register. The comparison result is a single mask bit of 1 (comparison true) or 0 (comparison false), written to the destination starting from the LSB according to the writemask k2. Bits (MAX_KL-1:128) of the destination register are cleared.</p>
<p>The comparison predicate operand is an 8-bit immediate:</p>
<p>The unordered relationship is true when at least one of the two source operands being compared is a NaN; the ordered relationship is true when neither source operand is a NaN.</p>
<p>A subsequent computational instruction that uses the mask result in the destination operand as an input operand will not generate an exception, because a mask of all 0s corresponds to a floating-point value of +0.0 and a mask of all 1s corresponds to a QNaN.</p>
<p>Note that processors with “CPUID.1H:ECX.AVX =0” do not implement the “greater-than”, “greater-than-or-equal”, “not-greater than”, and “not-greater-than-or-equal relations” predicates. These comparisons can be made either by using the inverse relationship (that is, use the “not-less-than-or-equal” to make a “greater-than” comparison)</p>
<p>or by using software emulation. When using software emulation, the program must swap the operands (copying registers when necessary to protect the data that will now be in the destination), and then perform the compare using a different predicate. The predicate to be used for these emulations is listed in the first 8 rows of Table 3-7 (<em>Intel 64 and IA-32 Architectures Software Developer’s Manual Volume 2A</em>) under the heading Emulation.</p>
<p>Compilers and assemblers may implement the following two-operand pseudo-ops in addition to the three-operand CMPSD instruction, for processors with “CPUID.1H:ECX.AVX =0”. See Table 3-6. Compiler should treat reserved Imm8 values as illegal syntax.</p>
<h3>Table 3-6. Pseudo-Op and CMPSD Implementation</h3>
<p>:</p>
<table>
<tr>
<th>Pseudo-Op</th>
<th>CMPSD Implementation</th></tr>
<tr>
<td>CMPEQSD x<em>mm1, xmm2</em></td>
<td>CMPSD x<em>mm1, xmm2, 0</em></td></tr>
<tr>
<td>CMPLTSD x<em>mm1, xmm2</em></td>
<td>CMPSD x<em>mm1, xmm2, 1</em></td></tr>
<tr>
<td>CMPLESD x<em>mm1, xmm2</em></td>
<td>CMPSD x<em>mm1, xmm2, 2</em></td></tr>
<tr>
<td>CMPUNORDSD x<em>mm1, xmm2</em></td>
<td>CMPSD x<em>mm1, xmm2, 3</em></td></tr>
<tr>
<td>CMPNEQSD x<em>mm1, xmm2</em></td>
<td>CMPSD x<em>mm1, xmm2, 4</em></td></tr>
<tr>
<td>CMPNLTSD x<em>mm1, xmm2</em></td>
<td>CMPSD x<em>mm1, xmm2, 5</em></td></tr>
<tr>
<td>CMPNLESD x<em>mm1, xmm2</em></td>
<td>CMPSD x<em>mm1, xmm2, 6</em></td></tr>
<tr>
<td>CMPORDSD x<em>mm1, xmm2</em></td>
<td>CMPSD x<em>mm1, xmm2, 7</em></td></tr></table>
<p>The greater-than relations that the processor does not implement require more than one instruction to emulate in software and therefore should not be implemented as pseudo-ops. (For these, the programmer should reverse the operands of the corresponding less than relations and use move instructions to ensure that the mask is moved to the correct destination register and that the source operand is left intact.)</p>
<p>Processors with “CPUID.1H:ECX.AVX =1” implement the full complement of 32 predicates shown in Table 3-7, soft-ware emulation is no longer needed. Compilers and assemblers may implement the following three-operand pseudo-ops in addition to the four-operand VCMPSD instruction. See Table 3-7, where the notations of reg1 reg2, and reg3 represent either XMM registers or YMM registers. Compiler should treat reserved Imm8 values as illegal syntax. Alternately, intrinsics can map the pseudo-ops to pre-defined constants to support a simpler intrinsic inter-face. Compilers and assemblers may implement three-operand pseudo-ops for EVEX encoded VCMPSD instructions in a similar fashion by extending the syntax listed in Table 3-7.</p>
<h3>Table 3-7. Pseudo-Op and VCMPSD Implementation</h3>
<p>:</p>
<table>
<tr>
<th>Pseudo-Op</th>
<th>CMPSD Implementation</th></tr>
<tr>
<td>VCMPEQSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 0</em></td></tr>
<tr>
<td>VCMPLTSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 1</em></td></tr>
<tr>
<td>VCMPLESD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 2</em></td></tr>
<tr>
<td>VCMPUNORDSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 3</em></td></tr>
<tr>
<td>VCMPNEQSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 4</em></td></tr>
<tr>
<td>VCMPNLTSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 5</em></td></tr>
<tr>
<td>VCMPNLESD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 6</em></td></tr>
<tr>
<td>VCMPORDSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 7</em></td></tr>
<tr>
<td>VCMPEQ_UQSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 8</em></td></tr>
<tr>
<td>VCMPNGESD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 9</em></td></tr>
<tr>
<td>VCMPNGTSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 0AH</em></td></tr>
<tr>
<td>VCMPFALSESD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 0BH</em></td></tr>
<tr>
<td>VCMPNEQ_OQSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 0CH</em></td></tr>
<tr>
<td>VCMPGESD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 0DH</em></td></tr></table>
<h3>Table 3-7. Pseudo-Op and VCMPSD Implementation</h3>
<table>
<tr>
<th>Pseudo-Op</th>
<th>CMPSD Implementation</th></tr>
<tr>
<td>VCMPGTSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 0EH</em></td></tr>
<tr>
<td>VCMPTRUESD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 0FH</em></td></tr>
<tr>
<td>VCMPEQ_OSSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 10H</em></td></tr>
<tr>
<td>VCMPLT_OQSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 11H</em></td></tr>
<tr>
<td>VCMPLE_OQSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 12H</em></td></tr>
<tr>
<td>VCMPUNORD_SSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 13H</em></td></tr>
<tr>
<td>VCMPNEQ_USSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 14H</em></td></tr>
<tr>
<td>VCMPNLT_UQSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 15H</em></td></tr>
<tr>
<td>VCMPNLE_UQSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 16H</em></td></tr>
<tr>
<td>VCMPORD_SSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 17H</em></td></tr>
<tr>
<td>VCMPEQ_USSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 18H</em></td></tr>
<tr>
<td>VCMPNGE_UQSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 19H</em></td></tr>
<tr>
<td>VCMPNGT_UQSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 1AH</em></td></tr>
<tr>
<td>VCMPFALSE_OSSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 1BH</em></td></tr>
<tr>
<td>VCMPNEQ_OSSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 1CH</em></td></tr>
<tr>
<td>VCMPGE_OQSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 1DH</em></td></tr>
<tr>
<td>VCMPGT_OQSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 1EH</em></td></tr>
<tr>
<td>VCMPTRUE_USSD r<em>eg1, reg2, reg3</em></td>
<td>VCMPSD r<em>eg1, reg2, reg3, 1FH</em></td></tr></table>
<p>Software should ensure VCMPSD is encoded with VEX.L=0. Encoding VCMPSD with VEX.L=1 may encounter unpre-dictable behavior across different processor generations.</p>
<h2>Operation</h2>
<pre>
CASE (COMPARISON PREDICATE) OF
0: OP3 (cid:197)EQ_OQ; OP5 (cid:197)EQ_OQ;
1: OP3 (cid:197)LT_OS; OP5 (cid:197)LT_OS;
2: OP3 (cid:197)LE_OS; OP5 (cid:197)LE_OS;
3: OP3 (cid:197)UNORD_Q; OP5 (cid:197)UNORD_Q;
4: OP3 (cid:197)NEQ_UQ; OP5 (cid:197)NEQ_UQ;
5: OP3 (cid:197)NLT_US; OP5 (cid:197)NLT_US;
6: OP3 (cid:197)NLE_US; OP5 (cid:197)NLE_US;
7: OP3 (cid:197)ORD_Q; OP5 (cid:197)ORD_Q;
8: OP5 (cid:197)EQ_UQ;
9: OP5 (cid:197)NGE_US;
10: OP5 (cid:197)NGT_US;
11: OP5 (cid:197)FALSE_OQ;
12: OP5 (cid:197)NEQ_OQ;
13: OP5 (cid:197)GE_OS;
14: OP5 (cid:197)GT_OS;
15: OP5 (cid:197)TRUE_UQ;
16: OP5 (cid:197)EQ_OS;
17: OP5 (cid:197)LT_OQ;
18: OP5 (cid:197)LE_OQ;
19: OP5 (cid:197)UNORD_S;
20: OP5 (cid:197)NEQ_US;
21: OP5 (cid:197)NLT_UQ;
22: OP5 (cid:197)NLE_UQ;
23: OP5 (cid:197)ORD_S;
24: OP5 (cid:197)EQ_US;
25: OP5 (cid:197)NGE_UQ;
26: OP5 (cid:197)NGT_UQ;
27: OP5 (cid:197)FALSE_OS;
28: OP5 (cid:197)NEQ_OS;
29: OP5 (cid:197)GE_OQ;
30: OP5 (cid:197)GT_OQ;
31: OP5 (cid:197)TRUE_US;
DEFAULT: Reserved
ESAC;
</pre>
<strong>VCMPSD (EVEX encoded version)</strong>
<pre>
CMP0 (cid:197) SRC1[63:0] OP5 SRC2[63:0];
IF k2[0] or *no writemask*
    THEN
    IF CMP0 = TRUE
        THEN DEST[0] (cid:197) 1;
        ELSE DEST[0] (cid:197) 0; FI;
    ELSE
    DEST[0] (cid:197) 0
    ; zeroing-masking only
FI;
DEST[MAX_KL-1:1] (cid:197) 0
</pre>
<strong>CMPSD (128-bit Legacy SSE version)</strong>
<pre>
CMP0 (cid:197)DEST[63:0] OP3 SRC[63:0];
IF CMP0 = TRUE
    THEN DEST[63:0] (cid:197)FFFFFFFFFFFFFFFFH;
    ELSE DEST[63:0] (cid:197)0000000000000000H; FI;
DEST[MAX_VL-1:64] (Unmodified)
</pre>
<strong>VCMPSD (VEX.128 encoded version)</strong>
<pre>
CMP0 (cid:197)SRC1[63:0] OP5 SRC2[63:0];
IF CMP0 = TRUE
    THEN DEST[63:0] (cid:197)FFFFFFFFFFFFFFFFH;
    ELSE DEST[63:0] (cid:197)0000000000000000H; FI;
DEST[127:64] (cid:197)SRC1[127:64]
DEST[MAX_VL-1:128] (cid:197)0
</pre>
<h2>Intel C/C++ Compiler Intrinsic Equivalent</h2>
<pre>
VCMPSD __mmask8 _mm_cmp_sd_mask( __m128d a, __m128d b, int imm);
VCMPSD __mmask8 _mm_cmp_round_sd_mask( __m128d a, __m128d b, int imm, int sae);
VCMPSD __mmask8 _mm_mask_cmp_sd_mask( __mmask8 k1, __m128d a, __m128d b, int imm);
VCMPSD __mmask8 _mm_mask_cmp_round_sd_mask( __mmask8 k1, __m128d a, __m128d b, int imm, int sae);
(V)CMPSD __m128d _mm_cmp_sd(__m128d a, __m128d b, const int imm)
</pre>
<h2>SIMD Floating-Point Exceptions</h2>
<p>Invalid if SNaN operand, Invalid if QNaN and predicate as listed in Table 3-1 Denormal.</p>
<h2>Other Exceptions</h2>
<table class="exception-table">
<tr>
<td>VEX-encoded instructions, see Exceptions Type 3.</td></tr>
<tr>
<td>EVEX-encoded instructions, see Exceptions Type E3.</td></tr></table>
</body>

<!-- Mirrored from shell-storm.org/x86doc/CMPSD.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 12 Sep 2023 17:02:58 GMT -->
</html>
